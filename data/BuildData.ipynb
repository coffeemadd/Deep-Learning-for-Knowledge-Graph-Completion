{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert embeddings into raw data\n",
    "Use the following to convert word embedding using's FaceBooks's fastText into raw data for a standard machine learning model. We are assuming a closed world solution with only positive and negative values for our 5 predicates - isChild, isSpouse, isFather, isMother, and isSibling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn as sk \n",
    "import scipy as sci \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the pickle files containing the word encodings and the entity map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = pickle.load(open('embeddings/large_set/random_init_word_vectors_clean_complete_large.pkl','rb'))\n",
    "key = pickle.load(open('processed/large_set/entities_map_large.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the files containing the positive and negative triplets of (entity,predicate,entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37395, 4), (4742, 4))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = dict.fromkeys(range(4), lambda s: s.decode('utf-8'))\n",
    "pos = np.loadtxt(r'processed/large_set/positiveTriplets_unique_large.txt',delimiter=' ',dtype=str, converters=converter)\n",
    "neg = np.loadtxt(r'processed/negativeTriplets_more.txt',delimiter=' ',dtype=str, converters=converter)\n",
    "pos.shape,neg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of the entities for looping over all of them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P22': 'isFather',\n",
       " 'P25': 'isMother',\n",
       " 'P26': 'isSpouse',\n",
       " 'P3373': 'isSibling',\n",
       " 'P40': 'isChild'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_key = {'P22':'isFather','P25':'isMother','P26':'isSpouse','P3373':'isSibling','P40':'isChild'}\n",
    "pred_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3195,), (5,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = np.unique(pos[:,0])\n",
    "predicates = np.unique(pos[:,1])\n",
    "entities.shape,predicates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few helper functions for the main data converting tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_word(word):\n",
    "    \"\"\"\n",
    "        Encodes a word if found in the word \n",
    "        encoding dictionary; otherwise returns\n",
    "        an empty array.\n",
    "    \"\"\"\n",
    "    if word in words.keys():\n",
    "        return(words[word])\n",
    "    max_len = max([words[x].shape[0] for x in words])\n",
    "    return(np.empty(max_len))\n",
    "\n",
    "def encode_entity(entity):\n",
    "    \"\"\"\n",
    "        Builds an entity encoding by computing\n",
    "        the average of all the word encodings.\n",
    "        Ignores any words that don't have an \n",
    "        encoding in the words_vectors.txt file.\n",
    "    \"\"\"\n",
    "    all_words = np.array([encode_word(x) for x in key[entity].split(' ') if x in words.keys()])\n",
    "    if all_words.shape[0]==0:\n",
    "        return(np.array([np.NaN]*300,dtype=float).transpose())\n",
    "    return(all_words.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary Function\n",
    "The build_rows function builds the appropriate rows of numerical data for a given entity. This is done by considering all triplets with this entity as the first object. Then it encodes all entities in this subset, including itself, and concatenates each encoding. Finally it looks as the predicate for each entity-entity pair and assigns 1,0, or -1 depending on if the predicate is true, unknown, or false for that entity-entity pair. The result is a small dataframe of all the rows of this form where the first entity is the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 607)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_rows(entity):\n",
    "    \"\"\"\n",
    "        Builds a dataframe out of the triplets\n",
    "        containing entity as the first object.\n",
    "    \"\"\"\n",
    "    encoding = encode_entity(entity)\n",
    "    temp_pos = pos[pos[:,0]==entity,:]\n",
    "    temp_neg = neg[neg[:,0]==entity,:]\n",
    "    pairs = []\n",
    "    rows = []\n",
    "    bad_encodings = []\n",
    "    for each_obj in np.unique(temp_pos[:,2]):        \n",
    "        try:\n",
    "            obj_encode = encode_entity(each_obj)\n",
    "            \n",
    "            if not all(np.isnan(obj_encode)):\n",
    "                # Get the positive & negative triplet's objects\n",
    "                temp2_pos = temp_pos[temp_pos[:,2]==each_obj,:]\n",
    "                temp2_neg = temp_neg[temp_neg[:,2]==each_obj,:]\n",
    "\n",
    "                # Build outputs from which predicates are in triplets\n",
    "                pos_preds = np.array([x in np.unique(temp2_pos[:,1]) for x in predicates],dtype=int)\n",
    "                neg_preds = np.array([x in np.unique(temp2_neg[:,1]) for x in predicates],dtype=int)\n",
    "                preds = pos_preds - neg_preds\n",
    "\n",
    "                # Update the data\n",
    "                row = np.concatenate([encoding,obj_encode,preds])\n",
    "                rows.append(row)\n",
    "                pairs.append([entity,each_obj])\n",
    "                \n",
    "            else:\n",
    "                #print('Entity ' + obj_encode + ' has no encoding!')\n",
    "                bad_encodings.append(each_obj)\n",
    "        except:\n",
    "            #print(\"didn't work for \"+ str(entity) + \", \" + str(each_obj))  \n",
    "            bad_encodings.append(each_obj)\n",
    " \n",
    "    rows = np.array(rows)\n",
    "    pairs = np.array(pairs)\n",
    "    if rows.shape[0] == 0:\n",
    "        return({'df':np.NaN,'bad_encodings':np.NaN})\n",
    "    df = pd.concat([pd.DataFrame(pairs),pd.DataFrame(rows)],ignore_index=True,axis=1)\n",
    "    col_names = ['EntityA','EntityB']+['a'+str(x) for x in range(300)]+['b'+str(x) for x in range(300)]+['p'+str(x) for x in range(5)]\n",
    "    df.columns = col_names\n",
    "    return({'df':df,'bad_encodings':bad_encodings})\n",
    "\n",
    "entity = \"Q107507\"\n",
    "test = build_rows(entity)['df']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running build_rows on all the entities to generate the main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Q1030337 failed!\n",
      "Entity: Q1030373 failed!\n",
      "Entity: Q103846 failed!\n",
      "Entity: Q10665 failed!\n",
      "Entity: Q106997 failed!\n",
      "Entity: Q108941 failed!\n",
      "Entity: Q10909274 failed!\n",
      "Entity: Q11071642 failed!\n",
      "Entity: Q11237 failed!\n",
      "Entity: Q1140914 failed!\n",
      "Entity: Q1147080 failed!\n",
      "Entity: Q11692700 failed!\n",
      "Entity: Q11765316 failed!\n",
      "Entity: Q11816 failed!\n",
      "Entity: Q119798 failed!\n",
      "Entity: Q123371 failed!\n",
      "Entity: Q1234340 failed!\n",
      "Entity: Q125606 failed!\n",
      "Entity: Q1284023 failed!\n",
      "Entity: Q129234 failed!\n",
      "Entity: Q1330169 failed!\n",
      "Entity: Q1333425 failed!\n",
      "Entity: Q1339 failed!\n",
      "Entity: Q13409406 failed!\n",
      "Entity: Q13909 failed!\n",
      "Entity: Q1398697 failed!\n",
      "Entity: Q145746 failed!\n",
      "Entity: Q146724 failed!\n",
      "Entity: Q147663 failed!\n",
      "Entity: Q1479982 failed!\n",
      "Entity: Q1508559 failed!\n",
      "Entity: Q151083 failed!\n",
      "Entity: Q151500 failed!\n",
      "Entity: Q1523 failed!\n",
      "Entity: Q152782 failed!\n",
      "Entity: Q1532 failed!\n",
      "Entity: Q153344 failed!\n",
      "Entity: Q153481 failed!\n",
      "Entity: Q156778 failed!\n",
      "Entity: Q158025 failed!\n",
      "Entity: Q158043 failed!\n",
      "Entity: Q158052 failed!\n",
      "Entity: Q158861 failed!\n",
      "Entity: Q15929912 failed!\n",
      "Entity: Q159369 failed!\n",
      "Entity: Q159934 failed!\n",
      "Entity: Q160353 failed!\n",
      "Entity: Q161389 failed!\n",
      "Entity: Q16166024 failed!\n",
      "Entity: Q161904 failed!\n",
      "Entity: Q168776 failed!\n",
      "Entity: Q1699735 failed!\n",
      "Entity: Q170026 failed!\n",
      "Entity: Q1701323 failed!\n",
      "Entity: Q17142943 failed!\n",
      "Entity: Q171465 failed!\n",
      "Entity: Q173795 failed!\n",
      "Entity: Q174323 failed!\n",
      "Entity: Q174367 failed!\n",
      "Entity: Q174762 failed!\n",
      "Entity: Q176455 failed!\n",
      "Entity: Q1770472 failed!\n",
      "Entity: Q182070 failed!\n",
      "Entity: Q183105 failed!\n",
      "Entity: Q18711120 failed!\n",
      "Entity: Q189660 failed!\n",
      "Entity: Q193506 failed!\n",
      "Entity: Q202725 failed!\n",
      "Entity: Q2063607 failed!\n",
      "Entity: Q206856 failed!\n",
      "Entity: Q2069573 failed!\n",
      "Entity: Q207 failed!\n",
      "Entity: Q21004359 failed!\n",
      "Entity: Q212852 failed!\n",
      "Entity: Q214677 failed!\n",
      "Entity: Q214999 failed!\n",
      "Entity: Q217096 failed!\n",
      "Entity: Q2190766 failed!\n",
      "Entity: Q221997 failed!\n",
      "Entity: Q228584 failed!\n",
      "Entity: Q2299910 failed!\n",
      "Entity: Q230303 failed!\n",
      "Entity: Q230636 failed!\n",
      "Entity: Q230654 failed!\n",
      "Entity: Q230863 failed!\n",
      "Entity: Q232094 failed!\n",
      "Entity: Q232380 failed!\n",
      "Entity: Q233253 failed!\n",
      "Entity: Q234131 failed!\n",
      "Entity: Q234665 failed!\n",
      "Entity: Q235641 failed!\n",
      "Entity: Q236135 failed!\n",
      "Entity: Q236999 failed!\n",
      "Entity: Q237324 failed!\n",
      "Entity: Q237636 failed!\n",
      "Entity: Q237907 failed!\n",
      "Entity: Q239411 failed!\n",
      "Entity: Q239678 failed!\n",
      "Entity: Q252290 failed!\n",
      "Entity: Q254 failed!\n",
      "Entity: Q254789 failed!\n",
      "Entity: Q255159 failed!\n",
      "Entity: Q2621911 failed!\n",
      "Entity: Q266030 failed!\n",
      "Entity: Q273739 failed!\n",
      "Entity: Q2794279 failed!\n",
      "Entity: Q2831 failed!\n",
      "Entity: Q287607 failed!\n",
      "Entity: Q28984 failed!\n",
      "Entity: Q2923664 failed!\n",
      "Entity: Q29419706 failed!\n",
      "Entity: Q295175 failed!\n",
      "Entity: Q296774 failed!\n",
      "Entity: Q297588 failed!\n",
      "Entity: Q299479 failed!\n",
      "Entity: Q303207 failed!\n",
      "Entity: Q30875 failed!\n",
      "Entity: Q309909 failed!\n",
      "Entity: Q309919 failed!\n",
      "Entity: Q310453 failed!\n",
      "Entity: Q313327 failed!\n",
      "Entity: Q313333 failed!\n",
      "Entity: Q313641 failed!\n",
      "Entity: Q31526 failed!\n",
      "Entity: Q318960 failed!\n",
      "Entity: Q319675 failed!\n",
      "Entity: Q3199788 failed!\n",
      "Entity: Q320829 failed!\n",
      "Entity: Q325016 failed!\n",
      "Entity: Q3305438 failed!\n",
      "Entity: Q334871 failed!\n",
      "Entity: Q3365 failed!\n",
      "Entity: Q342889 failed!\n",
      "Entity: Q34413 failed!\n",
      "Entity: Q344908 failed!\n",
      "Entity: Q347879 failed!\n",
      "Entity: Q3492647 failed!\n",
      "Entity: Q3524854 failed!\n",
      "Entity: Q3617765 failed!\n",
      "Entity: Q3634593 failed!\n",
      "Entity: Q363984 failed!\n",
      "Entity: Q3713655 failed!\n",
      "Entity: Q3714363 failed!\n",
      "Entity: Q37979 failed!\n",
      "Entity: Q380598 failed!\n",
      "Entity: Q380884 failed!\n",
      "Entity: Q389165 failed!\n",
      "Entity: Q40930 failed!\n",
      "Entity: Q41117 failed!\n",
      "Entity: Q41605 failed!\n",
      "Entity: Q4164300 failed!\n",
      "Entity: Q435203 failed!\n",
      "Entity: Q435793 failed!\n",
      "Entity: Q4395105 failed!\n",
      "Entity: Q44228 failed!\n",
      "Entity: Q442378 failed!\n",
      "Entity: Q448860 failed!\n",
      "Entity: Q449894 failed!\n",
      "Entity: Q457306 failed!\n",
      "Entity: Q458590 failed!\n",
      "Entity: Q4593 failed!\n",
      "Entity: Q465386 failed!\n",
      "Entity: Q466947 failed!\n",
      "Entity: Q467362 failed!\n",
      "Entity: Q467874 failed!\n",
      "Entity: Q470337 failed!\n",
      "Entity: Q47100 failed!\n",
      "Entity: Q4939864 failed!\n",
      "Entity: Q4951647 failed!\n",
      "Entity: Q5095188 failed!\n",
      "Entity: Q5236275 failed!\n",
      "Entity: Q5271122 failed!\n",
      "Entity: Q533883 failed!\n",
      "Entity: Q5363438 failed!\n",
      "Entity: Q548733 failed!\n",
      "Entity: Q554787 failed!\n",
      "Entity: Q56226 failed!\n",
      "Entity: Q60452 failed!\n",
      "Entity: Q604647 failed!\n",
      "Entity: Q6148319 failed!\n",
      "Entity: Q6187865 failed!\n",
      "Entity: Q6188555 failed!\n",
      "Entity: Q6198 failed!\n",
      "Entity: Q6513812 failed!\n",
      "Entity: Q6581540 failed!\n",
      "Entity: Q662282 failed!\n",
      "Entity: Q6639644 failed!\n",
      "Entity: Q6639729 failed!\n",
      "Entity: Q6779039 failed!\n",
      "Entity: Q6779916 failed!\n",
      "Entity: Q690708 failed!\n",
      "Entity: Q692 failed!\n",
      "Entity: Q692265 failed!\n",
      "Entity: Q7199764 failed!\n",
      "Entity: Q720 failed!\n",
      "Entity: Q7297 failed!\n",
      "Entity: Q730045 failed!\n",
      "Entity: Q74865 failed!\n",
      "Entity: Q7504 failed!\n",
      "Entity: Q7517 failed!\n",
      "Entity: Q7519 failed!\n",
      "Entity: Q754131 failed!\n",
      "Entity: Q76 failed!\n",
      "Entity: Q76179 failed!\n",
      "Entity: Q765682 failed!\n",
      "Entity: Q77895 failed!\n",
      "Entity: Q7841119 failed!\n",
      "Entity: Q8016 failed!\n",
      "Entity: Q807369 failed!\n",
      "Entity: Q81794 failed!\n",
      "Entity: Q850421 failed!\n",
      "Entity: Q850920 failed!\n",
      "Entity: Q855252 failed!\n",
      "Entity: Q86396 failed!\n",
      "Entity: Q882 failed!\n",
      "Entity: Q8916 failed!\n",
      "Entity: Q910463 failed!\n",
      "Entity: Q911334 failed!\n",
      "Entity: Q922651 failed!\n",
      "Entity: Q9256520 failed!\n",
      "Entity: Q932272 failed!\n",
      "Entity: Q96261 failed!\n",
      "Entity: Q962932 failed!\n",
      "Entity: Q9965 failed!\n",
      "Entity: Q9977 failed!\n"
     ]
    }
   ],
   "source": [
    "all_rows = pd.DataFrame([])\n",
    "bad_encodings = []\n",
    "for entity in entities:\n",
    "    rows = build_rows(entity)\n",
    "    try:\n",
    "        all_rows = pd.concat([all_rows,rows['df']])\n",
    "        [bad_encodings.append(x) for x in rows['bad_encodings']]\n",
    "    except:\n",
    "        print ('Entity: '+entity+ ' failed!')\n",
    "        bad_encodings.append(entity)\n",
    "        \n",
    "bad_encodings = np.unique(np.array(bad_encodings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_rows.to_csv('EncodedDataLrg.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode all entities and save as pickle file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Encoded = {entity:encode_entity(entity) for entity in entities}\n",
    "pickle.dump( Encoded, open( \"embeddings/entity_embeddings_lrg.pkl\", \"wb\" ) )\n",
    "pickle.dump( bad_encodings, open( \"embeddings/bad_entities_lrg.pkl\", \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
